{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT-Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XpGqdjRxTiR6",
        "TG8ZnkM4YCKS",
        "BBNya23MDvaA",
        "eMxWf36m7lUv"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAEgCNHL5joh",
        "colab_type": "text"
      },
      "source": [
        "https://docs.google.com/document/d/1QmoZJCeAjmaZQ2QQA3X2zqo9ET4PqSUT2frL4DX_Tdo/edit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3lyFtxvdyYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "bb709a03-1c5a-4d83-8893-101a965290bf"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install fasttext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3020481 sha256=31f886821f2c8f4d8659274cbae434eea28d153ea55e3c8cb73312ac5523b99f\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T41fYpZqCGyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "import re, string, nltk, spacy, random, os, io\n",
        "from collections import Counter\n",
        "from pickle import dump, load\n",
        "from unicodedata import normalize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jqb2vpZ4NbG",
        "colab_type": "code",
        "outputId": "7976be7e-50fa-4358-b3f1-bd4f42cc93ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch, keras\n",
        "import tensorflow_datasets as tfds\n",
        "import fasttext, fasttext.util\n",
        "from transformers import BertTokenizer, BertModel, BertConfig # bert-base-uncased\n",
        "from transformers import CamembertModel, CamembertTokenizer, CamembertConfig # camembert-base"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OOVcwiDu9NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sys.path.insert(0, '/content/drive/My Drive/')\n",
        "# from utils import clean_corpus, to_vocab, update_corpus, drop_nulls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7t3JY8aCsWW",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCzs2i4XxEt5",
        "colab_type": "text"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfoIh7w747mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_corpus(corpus):\n",
        "\tcleaned = list()\n",
        "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor line in corpus:\n",
        "\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "\t\tline = line.decode('UTF-8')\n",
        "\t\tline = line.split()\n",
        "\t\tline = [word.lower() for word in line]\n",
        "\t\tline = [word.translate(table) for word in line]\n",
        "\t\tline = [re_print.sub('', w) for w in line]\n",
        "\t\tline = [word for word in line if word.isalpha()]\n",
        "\t\tcleaned.append(' '.join(line))\n",
        "\treturn cleaned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM5V-WQO4609",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_vocab(corpus, min_occurance = 0):\n",
        "  tokenizer = keras.preprocessing.text.Tokenizer(filters='')\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  vocab = [k for k,v in tokenizer.word_counts.items() if v > min_occurance]\n",
        "  return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BUhRqPD46pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_corpus(corpus, vocab):\n",
        "\tclean_corpus = list()\n",
        "\tfor line in corpus:\n",
        "\t\tnew_tokens = list()\n",
        "\t\tfor token in line.split():\n",
        "\t\t\tif token in vocab:\n",
        "\t\t\t\tnew_tokens.append(token)\n",
        "\t\t\telse:\n",
        "\t\t\t\tnew_tokens.append('unk')\n",
        "\t\tnew_line = ' '.join(new_tokens)\n",
        "\t\tclean_corpus.append(new_line)\n",
        "\treturn clean_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZjUK68B46Rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def drop_nulls(corpus1, corpus2):\n",
        "    lengths = [len(line) for line in corpus1]\n",
        "    idx = [i for i,line in enumerate(corpus1) if len(line)>0]\n",
        "\n",
        "    corpus1 = [corpus1[i] for i in idx]\n",
        "    corpus2 = [corpus2[i] for i in idx]\n",
        "\n",
        "    return corpus1, corpus2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQAOISYmc1SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(corpus, min_occurance=5):\n",
        "  corpus = clean_corpus(corpus)\n",
        "  vocab = to_vocab(corpus, min_occurance)\n",
        "  corpus = update_corpus(corpus, vocab)\n",
        "  return corpus, vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBalzgK0EeF4",
        "colab_type": "text"
      },
      "source": [
        "## Small Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3DnM5xpC0vi",
        "colab_type": "code",
        "outputId": "71fe5249-833f-470b-df9a-58b689408878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "path = '/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/'\n",
        "files = os.listdir(path)\n",
        "files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['small_vocab_En.txt',\n",
              " 'small_vocab_Fr.txt',\n",
              " '.ipynb_checkpoints',\n",
              " 'en.pkl',\n",
              " 'fr.pkl',\n",
              " 'en_vocab.pkl',\n",
              " 'fr_vocab.pkl',\n",
              " 'en_ft_vocab.pkl',\n",
              " 'fr_ft_vocab.pkl',\n",
              " 'en_bert_vocab.pkl',\n",
              " 'fr_bert_vocab.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pCGWcgPEnrU",
        "colab_type": "code",
        "outputId": "126cf9b4-41ad-4ff8-abbe-49dd159baba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "en = open(path+files[0],'r').read().split('\\n')\n",
        "fr = open(path+files[1],'r').read().split('\\n')\n",
        "\n",
        "print(len(en), len(fr))\n",
        "print(en[:1])\n",
        "print(fr[:1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137860 137860\n",
            "['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n",
            "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHZ8fVbLEuwb",
        "colab_type": "code",
        "outputId": "82a3dd2d-0a03-45a6-a064-5307972777bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "en_lengths = [len(line.split()) for line in en]\n",
        "fr_lengths = [len(line.split()) for line in fr]\n",
        "\n",
        "print('Eng:',max(en_lengths), min(en_lengths))\n",
        "print('Fr:',max(fr_lengths), min(fr_lengths))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eng: 17 3\n",
            "Fr: 23 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzo41IqkdGa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en, en_vocab = preprocess(en)\n",
        "fr, fr_vocab = preprocess(fr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1AzePvl1GIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _ in range(3):\n",
        "  i = random.randint(0, len(en))\n",
        "  print(i,en[i])\n",
        "  print(i,fr[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp2BGW8mAsgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(en_vocab), len(fr_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip7IjGKtO6i6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dump(en_vocab, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/en_vocab.pkl', 'wb'))\n",
        "dump(fr_vocab, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/fr_vocab.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjjFJ06iyRLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dump(en, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/en.pkl', 'wb'))\n",
        "dump(fr, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/fr.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpGqdjRxTiR6",
        "colab_type": "text"
      },
      "source": [
        "## Europarl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lBPCMoZTjFU",
        "colab_type": "code",
        "outputId": "b1b155b9-fe9d-4526-d7c6-6d922f9ebf66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "path = '/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/'\n",
        "files = os.listdir(path)\n",
        "files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['english-fr.txt',\n",
              " 'french-en.txt',\n",
              " '.ipynb_checkpoints',\n",
              " 'en_vocab.pkl',\n",
              " 'fr_vocab.pkl',\n",
              " 'en.pkl',\n",
              " 'fr.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXNBRnX6Tinb",
        "colab_type": "code",
        "outputId": "1c5279c8-8024-443b-e8b2-f55ff671c0f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "en = open(path+files[0],'r').read().strip().split('\\n')\n",
        "fr = open(path+files[1],'r').read().strip().split('\\n')\n",
        "\n",
        "print(len(en), len(fr))\n",
        "print(en[:1])\n",
        "print(fr[:1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2007723 2007723\n",
            "['Resumption of the session']\n",
            "['Reprise de la session']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5siSu8tTsiT",
        "colab_type": "code",
        "outputId": "e61f7c08-2018-43c5-c37e-29173d4c97d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "en_lengths = [len(line.split()) for line in en]\n",
        "fr_lengths = [len(line.split()) for line in fr]\n",
        "print('Eng:',max(en_lengths), min(en_lengths))\n",
        "print('Fr:',max(fr_lengths), min(fr_lengths))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eng: 668 0\n",
            "Fr: 693 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCYQ4azRwsMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'en':en, 'fr':fr}).sample(n=32000, random_state=42)\n",
        "en, fr = df.en.values, df.fr.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_iGR09IvhEa",
        "colab_type": "code",
        "outputId": "e2782f76-5d15-4827-e2b5-69671d70c7e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "for _ in range(2):\n",
        "  i = random.randint(0, len(en))\n",
        "  print(i,en[i])\n",
        "  print(i,fr[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8999 They have suffered enough.\n",
            "8999 Ce peuple a assez souffert.\n",
            "26730 Mr President, Mr Sacrédeus has, I think, addressed something of essential importance.\n",
            "26730 Monsieur le Président, je suis d'avis que notre collègue Sacrédeus vient d'aborder un point essentiel.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnbYhjezJElN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en = clean_corpus(en)\n",
        "fr = clean_corpus(fr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqBApz98KCNN",
        "colab_type": "code",
        "outputId": "bf752118-240e-41f2-a06b-79fa2c70ec34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "print(len(en), len(fr))\n",
        "en, fr = drop_nulls(en, fr)\n",
        "print(len(en), len(fr))\n",
        "fr, en = drop_nulls(fr, en)\n",
        "print(len(en), len(fr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32000 32000\n",
            "31874 31874\n",
            "31832 31832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok5a58DDKJnW",
        "colab_type": "code",
        "outputId": "e40bb082-2d20-4012-9f0d-b01959294aaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "df = pd.DataFrame({'en':en, 'fr':fr}).sample(n=30000, random_state=42)\n",
        "en, fr = df.en.values, df.fr.values\n",
        "print(len(en), len(fr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8qGfkDzTsI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_vocab = to_vocab(en, min_occurance=5)\n",
        "en = update_corpus(en, en_vocab)\n",
        "fr_vocab = to_vocab(fr, min_occurance=5)\n",
        "fr = update_corpus(fr, fr_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3t2JpqDJ8p_",
        "colab_type": "code",
        "outputId": "5b2fa22a-944a-4cfb-e6dd-aa67a0b092cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "len(en_vocab), len(to_vocab(en)), len(fr_vocab), len(to_vocab(fr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6199, 6200, 7813, 7814)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UEZNmfha59R",
        "colab_type": "code",
        "outputId": "05c27942-fd90-43ab-812f-e527ef67030c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "en_lengths = [len(line.split()) for line in en]\n",
        "fr_lengths = [len(line.split()) for line in fr]\n",
        "\n",
        "print('Eng:',max(en_lengths), min(en_lengths))\n",
        "print('Fr:',max(fr_lengths), min(fr_lengths))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eng: 202 1\n",
            "Fr: 208 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2r_KqAMz8Ew",
        "colab_type": "code",
        "outputId": "20c8b62f-24f8-481a-feb3-be1e082df058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for _ in range(2):\n",
        "  i = random.randint(0, len(en))\n",
        "  print(i,en[i])\n",
        "  print(i,fr[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25748 what is the marking exactly\n",
            "25748 questce que le unk exactement\n",
            "713 honourable members in the last hour reports have reached me of what now appears to be a coordinated series of attacks on unk transport system\n",
            "713 honorables deputes au cours de lheure qui vient de unk jai recu des informations concernant ce qui apparait maintenant comme une serie unk coordonnes dans le systeme de transport unk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12RAT7C23AfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dump(en_vocab, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/en_vocab.pkl', 'wb'))\n",
        "dump(fr_vocab, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/fr_vocab.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igynLtT8YmDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dump(en, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/en.pkl', 'wb'))\n",
        "dump(fr, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/fr.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ztSBvH3z-6x",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG8ZnkM4YCKS",
        "colab_type": "text"
      },
      "source": [
        "#### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWhiHP3bV6mJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unk_vector(vocab):\n",
        "  vectors = np.array([v for k,v in vocab.items()])\n",
        "  vector = [np.mean(vectors[:,i]) for i in range(vectors.shape[1])]\n",
        "  return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L94hitDGVzSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_embeddings(vocab, model, tokenizer, special_chars):\n",
        "  text = ' '.join(list(vocab))\n",
        "  marked_text = special_chars[0] + text + special_chars[1]\n",
        "  tokens = tokenizer.tokenize(marked_text)\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  segments_ids = [1] * len(tokens)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "  with torch.no_grad():\n",
        "      encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
        "  embeddings = torch.squeeze(encoded_layers, dim=0)\n",
        "\n",
        "  return tokens, embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgZQn7h1YAMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_embs(vocab, words, embeddings, max_length):\n",
        "  bert_vocab = []\n",
        "  for word, idx in zip(vocab, words):\n",
        "    emb = np.mean(np.array([embeddings[i].numpy() for i in idx]), axis=0)\n",
        "    bert_vocab += [emb]\n",
        "  for i in range(max_length-len(vocab)):\n",
        "    bert_vocab += [np.zeros((768,))]\n",
        "  return bert_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRqmZEX6YA7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_tokens_en(tokens):\n",
        "  words = []\n",
        "  word = None\n",
        "  for i,t in enumerate(tokens[:-1]):\n",
        "    if i == 0: continue\n",
        "    if t[:2] == '##':\n",
        "      word += [i]\n",
        "    else:\n",
        "      if word is not None:\n",
        "        words += [word]\n",
        "      word = [i]\n",
        "  words += [word]\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs0uaKWBYILC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_tokens_fr(tokens):\n",
        "  words = []\n",
        "  word = None\n",
        "  for i,t in enumerate(tokens[:-1]):\n",
        "    if i == 0: continue\n",
        "    if t[0] == '▁':\n",
        "      if word is not None:\n",
        "        words += [word]\n",
        "      word = [i]\n",
        "    else:\n",
        "      word += [i]\n",
        "  words += [word]\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urSECV7M0aOy",
        "colab_type": "text"
      },
      "source": [
        "## Small Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4bVrYqDkVuY",
        "colab_type": "code",
        "outputId": "37ba0502-a367-4931-c866-95299de8d113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "en = load(open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/en.pkl', 'rb'))\n",
        "fr = load(open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/fr.pkl', 'rb'))\n",
        "len(en), len(fr)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137860, 137860)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4e6Bp5xKsbG",
        "colab_type": "code",
        "outputId": "486170f8-f15e-4250-a28b-0a259fc8d52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "en_vocab = load(open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/en_vocab.pkl', 'rb'))\n",
        "fr_vocab = load(open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/fr_vocab.pkl', 'rb'))\n",
        "fr_vocab += ['geles']\n",
        "len(en_vocab), len(fr_vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(199, 322)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBNya23MDvaA",
        "colab_type": "text"
      },
      "source": [
        "### FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQCkoC1ZDCPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft = fasttext.load_model('/content/drive/My Drive/Datasets/NLP/Models/FastText/cc.en.300.bin')\n",
        "en_ft_vocab = dict([(word, np.array(ft.get_word_vector(word))) for word in en_vocab])\n",
        "en_ft_vocab['unk'] = unk_vector(en_ft_vocab)\n",
        "en_ft_vocab['<start>'] = np.random.rand(300).tolist()\n",
        "en_ft_vocab['<end>'] = np.random.rand(300).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH8BOsm_S1Nx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "7ec5d000-7bd6-443d-e562-d15a2130245b"
      },
      "source": [
        "print(len(en_ft_vocab))\n",
        "dump(en_ft_vocab, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/en_ft_vocab.pkl', 'wb'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHehDqhDS4or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del en_ft_vocab, ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e894mOA7EyIg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "474a27ee-561c-4247-89d7-d0936137a77e"
      },
      "source": [
        "ft = fasttext.load_model('/content/drive/My Drive/Datasets/NLP/Models/FastText/cc.fr.300.bin')\n",
        "fr_ft_vocab = dict([(word, ft.get_word_vector(word)) for word in fr_vocab])\n",
        "fr_ft_vocab['unk'] = unk_vector(fr_ft_vocab)\n",
        "fr_ft_vocab['<start>'] = np.random.rand(300).tolist()\n",
        "fr_ft_vocab['<end>'] = np.random.rand(300).tolist()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr2Z_GIN6k4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(fr_ft_vocab))\n",
        "dump(fr_ft_vocab, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/fr_ft_vocab.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-5iuw99TpNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del fr_ft_vocab, ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjKGSVbI0doo",
        "colab_type": "text"
      },
      "source": [
        "## Europarl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR5SP1UBZAeQ",
        "colab_type": "code",
        "outputId": "c93aa248-95ba-4755-9c19-1812076d9727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "en = load(open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/en.pkl', 'rb'))\n",
        "fr = load(open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/fr.pkl', 'rb'))\n",
        "len(en), len(fr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 30000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiGLaVUk7hWq",
        "colab_type": "code",
        "outputId": "bf99dae9-aa55-45b7-ec0f-72aaa09af5dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "en_vocab = load(open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/en_vocab.pkl', 'rb'))\n",
        "fr_vocab = load(open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/fr_vocab.pkl', 'rb'))\n",
        "len(en_vocab), len(fr_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6199, 7813)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMxWf36m7lUv",
        "colab_type": "text"
      },
      "source": [
        "### FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71-0QYa67lu7",
        "colab_type": "code",
        "outputId": "badd38ee-cf99-467d-871e-56856328c790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "ft = fasttext.load_model('/content/drive/My Drive/Datasets/NLP/Models/FastText/cc.en.300.bin')\n",
        "en_ft_vocab = dict([(word, ft.get_word_vector(word)) for word in en_vocab])\n",
        "en_ft_vocab['unk'] = unk_vector(en_ft_vocab)\n",
        "en_ft_vocab['<start>'] = np.random.rand(300).tolist()\n",
        "en_ft_vocab['<end>'] = np.random.rand(300).tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mqjl-kd24IS",
        "colab_type": "code",
        "outputId": "358025aa-973b-4ba2-fb36-7d6f346995b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "print(len(en_vocab),len(en_ft_vocab))\n",
        "dump(en_ft_vocab, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/en_ft_vocab.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6199 6202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbNBRflR8bDT",
        "colab_type": "code",
        "outputId": "e353dc50-e081-4927-e5ea-7e0fb6274bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "ft = fasttext.load_model('/content/drive/My Drive/Datasets/NLP/Models/FastText/cc.fr.300.bin')\n",
        "fr_ft_vocab = dict([(word, ft.get_word_vector(word)) for word in fr_vocab])\n",
        "fr_ft_vocab['unk'] = unk_vector(fr_ft_vocab)\n",
        "fr_ft_vocab['<start>'] = np.random.rand(300).tolist()\n",
        "fr_ft_vocab['<end>'] = np.random.rand(300).tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BoqVUZQ7rm1",
        "colab_type": "code",
        "outputId": "af729693-5be8-489d-ebeb-b0e9be18422f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "print(len(fr_vocab), len(fr_ft_vocab))\n",
        "dump(fr_ft_vocab, open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Europarl/fr_ft_vocab.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7813 7816\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}