{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT-RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IYvTK1VM5yxt",
        "BgH0SQTS5qL4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXCi9DnIvZsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, string, nltk, spacy\n",
        "import os, sys, csv, random, time, datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns; sns.set(style='whitegrid')\n",
        "from collections import Counter\n",
        "from pickle import dump, load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qb_oD7Bw6J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7VCqD_BxkW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(corpus):\n",
        "  corpus = ['<start> '+line+' <end>' for line in corpus]\n",
        "  tokenizer = keras.preprocessing.text.Tokenizer(filters='')\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  tensor = tokenizer.texts_to_sequences(corpus)\n",
        "  tensor = keras.preprocessing.sequence.pad_sequences(tensor,  padding='post')\n",
        "\n",
        "  return tensor, tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYvTK1VM5yxt",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7UMztyeyZqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en = load(open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/en.pkl', 'rb')) \n",
        "fr = load(open('/content/drive/My Drive/Datasets/NLP/MT/French-English/Small Vocab/fr.pkl', 'rb')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTZds9a2yZkI",
        "colab_type": "code",
        "outputId": "e8e31f81-06c3-4aae-92e1-bcbd4dfab551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "input_tensor, inp_lang = tokenize(en)\n",
        "target_tensor, targ_lang = tokenize(fr)\n",
        "input_tensor.shape, target_tensor.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((137860, 17), (137860, 23))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p_xp5g1yPiV",
        "colab_type": "code",
        "outputId": "db77e261-c0bb-470f-d282-7de2a1c8ce6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(input_tensor, target_tensor, test_size=0.2, random_state=42)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(110288, 17) (27572, 17) (110288, 23) (27572, 23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef8CrC-1yPdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buffer_size = input_tensor.shape[0]\n",
        "batch_size = 64\n",
        "steps_per_epoch = len(X_train)//batch_size\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "print(vocab_inp_size, vocab_tar_size)\n",
        "print(max_length_targ, max_length_inp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bSMTIOIV-at",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgH0SQTS5qL4",
        "colab_type": "text"
      },
      "source": [
        "### Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcAz8QSGh0H1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units \n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0OUhOzpdzxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(hidden, 1), x], axis=-1)\n",
        "    output, state = self.gru(x)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhPMXSWcdzwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUm_ix4pdzrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * batch_size, 1)\n",
        "\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0ZhEo2g5uxa",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUksIe8ReZiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, batch_size)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6I7tP0beZg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "b67008d6-7ecd-474c-d260-7f2c6f7b5a4c"
      },
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/Datasets/NLP/Checkpoints/RNN/embedding'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f691d9a20f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ezwv35HeZZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "EPOCHS = 50\n",
        "  \n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrVOZhbUeZN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=max_length_inp,padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden = decoder(dec_input,dec_hidden,enc_out)\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  print(len(result))\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlLAHx3LNvBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result = evaluate(sentence)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4PJ3L0QeZMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = inp_lang.sequences_to_texts([input_tensor[0]])[0]\n",
        "tar = targ_lang.sequences_to_texts([target_tensor[0]])[0]\n",
        "pred = translate(inp)\n",
        "print(pred)\n",
        "print(tar)\n",
        "print(inp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnl1ptc8eZGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = []\n",
        "with open('/content/drive/My Drive/Datasets/NLP/Predictions/RNN/predictions.txt','w') as f:\n",
        "  for i, (x,y) in enumerate(zip(X_test, y_test)):\n",
        "    sentence = inp_lang.sequences_to_texts([x])[0]\n",
        "    pred = translate(sentence)\n",
        "    y = ' '.join(targ_lang.sequences_to_texts([y])[0].split(' ')[1:-1])\n",
        "    pred = ' '.join(pred.split(' ')[:-2])\n",
        "    df += [[y, pred]]\n",
        "    if i % 1000 == 0: \n",
        "      print(i)\n",
        "      for line in df:\n",
        "        f.write(line[0]+'\\t'+line[1]+'\\n')\n",
        "      df = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FiUg2sReY7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = pd.read_csv('/content/drive/My Drive/Datasets/NLP/Predictions/RNN/predictions.txt', sep='\\t', header=None)\n",
        "predictions.drop_duplicates(inplace=True)\n",
        "print(predictions.shape)\n",
        "predictions.head(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSnfCOHPh-Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pd1UJj7SpeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true = predictions[0].values\n",
        "pred = predictions[1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OngFD-PXSsOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "3596610d-0c28-46b8-bdee-ca69180f4a60"
      },
      "source": [
        "score = [0,0,0]\n",
        "for i, (y,p) in enumerate(zip(true,pred)):\n",
        "  score[0] += sentence_bleu(y, p)\n",
        "  score[1] += sentence_bleu(y, p, smoothing_function=SmoothingFunction().method1)\n",
        "  score[2] += sentence_bleu(y, p, smoothing_function=SmoothingFunction().method2)\n",
        "\n",
        "print(score[0]/predictions.shape[0])\n",
        "print(score[1]/predictions.shape[0])\n",
        "print(score[2]/predictions.shape[0])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7090127815964198\n",
            "0.0058034304373505196\n",
            "0.032554179613585484\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}